#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
List to YAML Converter for Mihomo/Clash Rules
ä»æŒ‡å®šURLä¸‹è½½.listæ–‡ä»¶å¹¶è½¬æ¢ä¸º.yamlæ ¼å¼
"""

import os
import re
import sys
from urllib.request import urlopen, Request
from urllib.error import URLError, HTTPError
from typing import Dict, List, Tuple


# æ”¯æŒçš„è§„åˆ™ç±»å‹ï¼ˆYAMLæ ¼å¼æ”¯æŒçš„ç±»å‹ï¼‰
SUPPORTED_RULE_TYPES = {
    'DOMAIN-SUFFIX',
    'DOMAIN-KEYWORD',
    'IP-CIDR',
    'IP-CIDR6',
    'DOMAIN',
    'DOMAIN-SET',
    'GEOIP',
    'IP-ASN',
}

# ä¸æ”¯æŒçš„è§„åˆ™ç±»å‹ï¼ˆéœ€è¦è¿‡æ»¤æ‰ï¼‰
UNSUPPORTED_RULE_TYPES = {
    'USER-AGENT',
    'URL-REGEX',
    'PROCESS-NAME',
}


def download_file(url: str) -> Tuple[str, str]:
    """
    ä¸‹è½½æ–‡ä»¶
    
    Args:
        url: æ–‡ä»¶URL
    
    Returns:
        (æ–‡ä»¶å†…å®¹, æ–‡ä»¶å)
    """
    print(f"ğŸ“¥ æ­£åœ¨ä¸‹è½½: {url}")
    
    try:
        # æ·»åŠ User-Agentä»¥é¿å…è¢«æŸäº›æœåŠ¡å™¨æ‹’ç»
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        request = Request(url, headers=headers)
        
        with urlopen(request, timeout=30) as response:
            content = response.read().decode('utf-8')
            
            # ä»URLä¸­æå–æ–‡ä»¶å
            filename = url.split('/')[-1]
            
            print(f"âœ“ ä¸‹è½½æˆåŠŸ: {filename} ({len(content)} å­—èŠ‚)")
            return content, filename
    
    except HTTPError as e:
        print(f"âœ— HTTPé”™è¯¯ {e.code}: {url}")
        raise
    except URLError as e:
        print(f"âœ— URLé”™è¯¯: {e.reason}")
        raise
    except Exception as e:
        print(f"âœ— ä¸‹è½½å¤±è´¥: {e}")
        raise


def parse_list_file(content: str, filename: str) -> Dict:
    """
    è§£æ.listæ–‡ä»¶å†…å®¹
    
    Args:
        content: æ–‡ä»¶å†…å®¹
        filename: æ–‡ä»¶å
    
    Returns:
        åŒ…å«å…ƒæ•°æ®å’Œè§„åˆ™çš„å­—å…¸
    """
    print(f"\nğŸ“‹ è§£ææ–‡ä»¶: {filename}")
    
    lines = content.strip().split('\n')
    
    metadata = {
        'NAME': '',
        'AUTHOR': '',
        'REPO': '',
        'UPDATED': '',
        'DOMAIN-KEYWORD': 0,
        'DOMAIN-SUFFIX': 0,
        'IP-CIDR': 0,
        'IP-CIDR6': 0,
        'TOTAL': 0,
    }
    
    rules = []
    stats = {}
    skipped_rules = []
    
    for line_num, line in enumerate(lines, 1):
        line = line.strip()
        
        # è§£ææ³¨é‡Šä¸­çš„å…ƒæ•°æ®
        if line.startswith('#'):
            # æå–å…ƒæ•°æ®
            for key in ['NAME', 'AUTHOR', 'REPO', 'UPDATED']:
                if f'# {key}:' in line:
                    metadata[key] = line.split(':', 1)[1].strip()
            
            # æå–ç»Ÿè®¡ä¿¡æ¯
            for key in ['DOMAIN-KEYWORD', 'DOMAIN-SUFFIX', 'IP-CIDR', 'IP-CIDR6', 'TOTAL']:
                if f'# {key}:' in line:
                    try:
                        metadata[key] = int(line.split(':', 1)[1].strip())
                    except:
                        pass
            continue
        
        # è·³è¿‡ç©ºè¡Œ
        if not line:
            continue
        
        # è§£æè§„åˆ™
        parts = line.split(',')
        if len(parts) < 2:
            continue
        
        rule_type = parts[0].strip()
        rule_value = parts[1].strip()
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºæ”¯æŒçš„è§„åˆ™ç±»å‹
        if rule_type in UNSUPPORTED_RULE_TYPES:
            skipped_rules.append((line_num, rule_type, rule_value))
            continue
        
        if rule_type not in SUPPORTED_RULE_TYPES:
            print(f"  âš ï¸  ç¬¬{line_num}è¡Œ: æœªçŸ¥è§„åˆ™ç±»å‹ '{rule_type}' - {line}")
            continue
        
        # å¤„ç†IP-CIDRè§„åˆ™ï¼ˆç§»é™¤no-resolveç­‰å‚æ•°ï¼‰
        if rule_type in ['IP-CIDR', 'IP-CIDR6']:
            # åªä¿ç•™IPåœ°å€éƒ¨åˆ†ï¼Œå»æ‰no-resolveç­‰å‚æ•°
            final_rule = f"{rule_type},{rule_value}"
        else:
            final_rule = f"{rule_type},{rule_value}"
        
        rules.append(final_rule)
        
        # ç»Ÿè®¡
        stats[rule_type] = stats.get(rule_type, 0) + 1
    
    # è¾“å‡ºè§£æç»Ÿè®¡
    print(f"\n  è§£æç»Ÿè®¡:")
    print(f"  - æ€»è¡Œæ•°: {len(lines)}")
    print(f"  - æœ‰æ•ˆè§„åˆ™: {len(rules)}")
    
    if stats:
        print(f"\n  è§„åˆ™ç±»å‹åˆ†å¸ƒ:")
        for rule_type, count in sorted(stats.items()):
            print(f"    â€¢ {rule_type}: {count}")
    
    if skipped_rules:
        print(f"\n  âš ï¸  è·³è¿‡çš„ä¸æ”¯æŒè§„åˆ™: {len(skipped_rules)}")
        for line_num, rule_type, rule_value in skipped_rules[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"    ç¬¬{line_num}è¡Œ: {rule_type},{rule_value}")
        if len(skipped_rules) > 5:
            print(f"    ... è¿˜æœ‰ {len(skipped_rules) - 5} ä¸ª")
    
    return {
        'metadata': metadata,
        'rules': rules,
        'stats': stats
    }


def convert_to_yaml(data: Dict, original_filename: str) -> str:
    """
    è½¬æ¢ä¸ºYAMLæ ¼å¼
    
    Args:
        data: è§£æåçš„æ•°æ®
        original_filename: åŸå§‹æ–‡ä»¶å
    
    Returns:
        YAMLæ ¼å¼çš„å­—ç¬¦ä¸²
    """
    print(f"\nğŸ”„ è½¬æ¢ä¸ºYAMLæ ¼å¼...")
    
    metadata = data['metadata']
    rules = data['rules']
    stats = data['stats']
    
    # æ„å»ºYAMLå†…å®¹
    yaml_lines = []
    
    # æ·»åŠ æ³¨é‡Šå¤´
    yaml_lines.append(f"# NAME: {metadata.get('NAME', '')}")
    yaml_lines.append(f"# AUTHOR: {metadata.get('AUTHOR', '')}")
    yaml_lines.append(f"# REPO: {metadata.get('REPO', '')}")
    yaml_lines.append(f"# UPDATED: {metadata.get('UPDATED', '')}")
    
    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    for key in ['DOMAIN-KEYWORD', 'DOMAIN-SUFFIX', 'IP-CIDR', 'IP-CIDR6']:
        if key in stats:
            yaml_lines.append(f"# {key}: {stats[key]}")
    
    yaml_lines.append(f"# TOTAL: {len(rules)}")
    
    # æ·»åŠ payloadéƒ¨åˆ†
    yaml_lines.append("payload:")
    
    for rule in rules:
        yaml_lines.append(f"  - {rule}")
    
    yaml_content = '\n'.join(yaml_lines)
    
    print(f"âœ“ è½¬æ¢å®Œæˆï¼Œå…± {len(rules)} æ¡è§„åˆ™")
    
    return yaml_content


def save_yaml_file(content: str, filename: str, output_dir: str = '.') -> str:
    """
    ä¿å­˜YAMLæ–‡ä»¶
    
    Args:
        content: YAMLå†…å®¹
        filename: åŸå§‹æ–‡ä»¶å
        output_dir: è¾“å‡ºç›®å½•
    
    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    # å°†.liståç¼€æ”¹ä¸º.yaml
    yaml_filename = filename.replace('.list', '.yaml')
    yaml_path = os.path.join(output_dir, yaml_filename)
    
    with open(yaml_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print(f"ğŸ’¾ ä¿å­˜æ–‡ä»¶: {yaml_path}")
    
    return yaml_path


def merge_yaml_files(yaml_contents: List[Tuple[str, str]], output_dir: str = '.') -> str:
    """
    åˆå¹¶å¤šä¸ªYAMLæ–‡ä»¶ä¸ºä¸€ä¸ª
    
    Args:
        yaml_contents: [(æ–‡ä»¶å, YAMLå†…å®¹), ...] åˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
    
    Returns:
        åˆå¹¶åçš„æ–‡ä»¶è·¯å¾„
    """
    print(f"\nğŸ”— åˆå¹¶æ‰€æœ‰YAMLæ–‡ä»¶...")
    
    merged_lines = []
    
    # æ·»åŠ åˆå¹¶æ–‡ä»¶çš„å¤´éƒ¨æ³¨é‡Š
    merged_lines.append("# NAME: Merged Proxy DNS Rules")
    merged_lines.append("# AUTHOR: Auto-generated")
    merged_lines.append(f"# TOTAL FILES: {len(yaml_contents)}")
    
    # ç»Ÿè®¡æ€»è§„åˆ™æ•°
    total_rules = 0
    rule_stats = {}
    
    # æ”¶é›†æ‰€æœ‰è§„åˆ™ï¼ˆå»é‡ï¼‰
    all_rules = []
    seen_rules = set()
    
    for filename, content in yaml_contents:
        merged_lines.append(f"# SOURCE: {filename}")
        
        # è§£ææ¯ä¸ªæ–‡ä»¶çš„è§„åˆ™
        lines = content.split('\n')
        for line in lines:
            stripped = line.strip()
            
            # è·³è¿‡æ³¨é‡Šå’Œpayloadæ ‡è®°
            if stripped.startswith('#') or stripped == 'payload:':
                continue
            
            # æå–è§„åˆ™ï¼ˆç§»é™¤å‰å¯¼çš„ "  - "ï¼‰
            if stripped.startswith('- '):
                rule = stripped[2:].strip()
                
                # å»é‡
                if rule and rule not in seen_rules:
                    seen_rules.add(rule)
                    all_rules.append(rule)
                    
                    # ç»Ÿè®¡è§„åˆ™ç±»å‹
                    rule_type = rule.split(',')[0]
                    rule_stats[rule_type] = rule_stats.get(rule_type, 0) + 1
                    total_rules += 1
    
    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    merged_lines.append("#")
    merged_lines.append("# Rule Statistics:")
    for rule_type, count in sorted(rule_stats.items()):
        merged_lines.append(f"# {rule_type}: {count}")
    merged_lines.append(f"# TOTAL: {total_rules}")
    merged_lines.append("#")
    
    # æ·»åŠ payloadéƒ¨åˆ†
    merged_lines.append("payload:")
    for rule in all_rules:
        merged_lines.append(f"  - {rule}")
    
    merged_content = '\n'.join(merged_lines)
    
    # ä¿å­˜åˆå¹¶æ–‡ä»¶
    merged_path = os.path.join(output_dir, 'need-proxy-dns.yaml')
    with open(merged_path, 'w', encoding='utf-8') as f:
        f.write(merged_content)
    
    print(f"âœ“ åˆå¹¶å®Œæˆ")
    print(f"  - æºæ–‡ä»¶æ•°: {len(yaml_contents)}")
    print(f"  - æ€»è§„åˆ™æ•°: {total_rules} (å»é‡å)")
    print(f"ğŸ’¾ ä¿å­˜åˆå¹¶æ–‡ä»¶: {merged_path}")
    
    return merged_path


def process_url(url: str, output_dir: str = '.', keep_list: bool = False) -> Tuple[bool, str, str]:
    """
    å¤„ç†å•ä¸ªURL
    
    Args:
        url: ä¸‹è½½URL
        output_dir: è¾“å‡ºç›®å½•
        keep_list: æ˜¯å¦ä¿ç•™åŸå§‹.listæ–‡ä»¶
    
    Returns:
        (æ˜¯å¦æˆåŠŸ, æ–‡ä»¶å, YAMLå†…å®¹)
    """
    try:
        # 1. ä¸‹è½½æ–‡ä»¶
        content, filename = download_file(url)
        
        # ä¿å­˜åŸå§‹.listæ–‡ä»¶ï¼ˆä¸´æ—¶ï¼‰
        list_path = os.path.join(output_dir, filename)
        with open(list_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        # 2. è§£ææ–‡ä»¶
        data = parse_list_file(content, filename)
        
        # 3. è½¬æ¢ä¸ºYAML
        yaml_content = convert_to_yaml(data, filename)
        
        # 4. ä¿å­˜YAMLæ–‡ä»¶
        yaml_path = save_yaml_file(yaml_content, filename, output_dir)
        
        # 5. åˆ é™¤åŸå§‹.listæ–‡ä»¶ï¼ˆé™¤éæŒ‡å®šä¿ç•™ï¼‰
        if not keep_list and os.path.exists(list_path):
            os.remove(list_path)
            print(f"ğŸ—‘ï¸  åˆ é™¤åŸå§‹æ–‡ä»¶: {list_path}")
        
        print(f"\n{'='*60}")
        print(f"âœ… æˆåŠŸå¤„ç†: {filename} -> {os.path.basename(yaml_path)}")
        print(f"{'='*60}\n")
        
        return True, filename, yaml_content
    
    except Exception as e:
        print(f"\nâŒ å¤„ç†å¤±è´¥: {url}")
        print(f"   é”™è¯¯: {e}\n")
        return False, "", ""


def main():
    """ä¸»å‡½æ•°"""
    # ä¸‹è½½URLåˆ—è¡¨çš„åœ°å€
    download_list_url = "https://raw.githubusercontent.com/Shinlor/ForPersonalUse/refs/heads/main/downloadurl.list"
    
    print("="*60)
    print("List to YAML è½¬æ¢å·¥å…·")
    print("="*60)
    print(f"\nğŸ“ ä¸‹è½½åˆ—è¡¨URL: {download_list_url}\n")
    
    try:
        # ä¸‹è½½URLåˆ—è¡¨
        list_content, _ = download_file(download_list_url)
        
        # è§£æURLåˆ—è¡¨
        urls = [line.strip() for line in list_content.split('\n') 
                if line.strip() and not line.strip().startswith('#')]
        
        print(f"\nğŸ“Š æ‰¾åˆ° {len(urls)} ä¸ªä¸‹è½½é“¾æ¥\n")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = './converted_rules'
        os.makedirs(output_dir, exist_ok=True)
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}\n")
        
        # å¤„ç†æ¯ä¸ªURL
        success_count = 0
        fail_count = 0
        yaml_contents = []  # å­˜å‚¨æ‰€æœ‰æˆåŠŸè½¬æ¢çš„YAMLå†…å®¹
        
        for i, url in enumerate(urls, 1):
            print(f"\n[{i}/{len(urls)}] å¤„ç†: {url}")
            print("-"*60)
            
            success, filename, yaml_content = process_url(url, output_dir, keep_list=False)
            if success:
                success_count += 1
                yaml_contents.append((filename.replace('.list', '.yaml'), yaml_content))
            else:
                fail_count += 1
        
        # åˆå¹¶æ‰€æœ‰YAMLæ–‡ä»¶
        if yaml_contents:
            print("\n" + "="*60)
            merge_yaml_files(yaml_contents, output_dir)
            print("="*60)
        
        # è¾“å‡ºæ€»ç»“
        print("\n" + "="*60)
        print("è½¬æ¢å®Œæˆæ€»ç»“")
        print("="*60)
        print(f"âœ… æˆåŠŸ: {success_count}")
        print(f"âŒ å¤±è´¥: {fail_count}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        if yaml_contents:
            print(f"ğŸ”— åˆå¹¶æ–‡ä»¶: {os.path.join(output_dir, 'need-proxy-dns.yaml')}")
        print("="*60)
        
    except Exception as e:
        print(f"\nâŒ ç¨‹åºé”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
